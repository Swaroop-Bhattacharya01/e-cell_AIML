# -*- coding: utf-8 -*-
"""e-cell_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lS1JXRHRbljg8pzeXXqa1LIGgEgQ9ukp

# DATA PROCESSING
"""

import pandas as pd

df=pd.read_csv('/content/startup_funding.csv')

df.info()

df = df.dropna(subset=['Industry Vertical','City  Location','Amount in USD'])
df = df[df['Amount in USD'].str.replace(',', '').str.isnumeric()]
df['Amount in USD'] = df['Amount in USD'].str.replace(',', '').astype(float)

df = df.dropna(subset=['Industry Vertical','City  Location','Amount in USD'])

median_funding = df['Amount in USD'].median()
df['Success'] = (df['Amount in USD'] >= median_funding).astype(int)

from sklearn.preprocessing import LabelEncoder

from sklearn.preprocessing import LabelEncoder

for col in ['Industry Vertical', 'City  Location', 'InvestmentnType']:
    df[col] = LabelEncoder().fit_transform(df[col].astype(str))

features = ['Industry Vertical', 'City  Location', 'InvestmentnType', 'Amount in USD']
X = df[features]
y = df['Success']

from sklearn.preprocessing import LabelEncoder,StandardScaler

scaler = StandardScaler()
X.loc[:, ['Amount in USD']] = scaler.fit_transform(X[['Amount in USD']])

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(X_train, y_train)

y_pred_lr = lr.predict(X_test)

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

y_pred_rf = rf.predict(X_test)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def print_metrics(model_name, y_true, y_pred):
    print(f"{model_name}:")
    print("Accuracy:", accuracy_score(y_true, y_pred))
    print("Precision:", precision_score(y_true, y_pred))
    print("Recall:", recall_score(y_true, y_pred))
    print("F1:", f1_score(y_true, y_pred))

print_metrics("Logistic Regression", y_test, y_pred_lr)
print_metrics("Random Forest", y_test, y_pred_rf)

"""# **HYPERPARAMETER TUNING**

## for linear regression
"""

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

param_grid_lr = [
    {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']},
    {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l2'], 'solver': ['lbfgs']}
]

lr = LogisticRegression(max_iter=1000)

grid_lr = GridSearchCV(lr, param_grid_lr, cv=3, n_jobs=-1)
grid_lr.fit(X_train, y_train)

print("Best Logistic Regression Params:", grid_lr.best_params_)
print("Best Logistic Regression F1:", grid_lr.best_score_)

y_pred_lr_best = grid_lr.best_estimator_.predict(X_test)

"""## FOR RANDOM FOREST

"""

param_grid_rf = {
    'n_estimators': [10, 50, 100, 500],
    'max_depth': [3, 5, 7, 9],
    'min_samples_split': [2, 5, 10]
}

rf = RandomForestClassifier(random_state=42)
grid_rf = GridSearchCV(rf, param_grid_rf, cv=3, n_jobs=-1)
grid_rf.fit(X_train, y_train)

print("Best Random Forest Params:", grid_rf.best_params_)
print("Best Random Forest F1:", grid_rf.best_score_)

y_pred_rf_best = grid_rf.best_estimator_.predict(X_test)

print_metrics("Logistic Regression", y_test, y_pred_lr_best)
print_metrics("Random Forest", y_test, y_pred_rf_best)

